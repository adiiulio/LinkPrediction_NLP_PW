{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:07:53.387384Z",
     "iopub.status.busy": "2025-07-26T19:07:53.386875Z",
     "iopub.status.idle": "2025-07-26T19:07:57.989083Z",
     "shell.execute_reply": "2025-07-26T19:07:57.988316Z",
     "shell.execute_reply.started": "2025-07-26T19:07:53.387359Z"
    },
    "id": "C_-x0nDpVHK6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382,
     "referenced_widgets": [
      "161300e40b1744e792190574d8f1ae4e",
      "908cf0621e5f449d848a8e0358103aae",
      "3f03cb71ffa84260a55747417ccd5b7e",
      "2e86fc6f454f4520987cbb74c19aeb58",
      "49e0b0c891f7425c9a7f236498a4c8e3",
      "5182a1048b0f46e7b9b3087f64895c75",
      "039f6eb2e4c8465893abc04dd897fd63",
      "5f62831d6dec4c5199029f6678a78c5e",
      "07f665e4e3324af1a63973df96b2f74e",
      "6aa5e640ee7c42d88578521b0fde8b5f",
      "16c5cad737434496b160b58c0995a0fa",
      "9ca88f1eb1d343fba0d88360fcbfb35e",
      "0e197d7762c445d48d85a842fb6b0fb3",
      "c5176e5c1e2b4d128dfed67b6d42430e",
      "f4faaa22ff194f5198526db3f9716768",
      "a8ec611fd2164cb6af775b27be82e975",
      "f29954f9f3514f2faa4b88c1a05be0f0",
      "1b81b0b7f0f744868f10d62081e60db1",
      "bdd7a700989a4e8e8f8d6140e2df216e",
      "4f5d3f3e1bc643a886f348789e7bf52d",
      "b68b364298f240c19c1dacbb6ab6d4ab",
      "f8d8517ab2d548e8b761f1e1c6020b6b",
      "3d89dbecab9a451386701db0fb8f1ac6",
      "ccea143913c14cf9b6b6d36ba4537003",
      "d418908020b641148e4150da379e32a5",
      "4fa04f2cb0344c36add0912d6fea57e7",
      "7b8125dc670f48bd8c43ac9ba185446b",
      "bbc04c2832f2418cb3941922ba0fe322",
      "946bc785bc2b463baf66d20f049725a4",
      "b68e751ffd2d440c9c46cd9b16d51293",
      "5af62ace21344c0eb832f08763ccb2dd",
      "bd4c6764b9ab4ef98fa42f8caa3c41b0",
      "d9841c70b30640438b97a2d24512d3cc",
      "b7c9a7fdfcda4691a3ecf60e24a35e67",
      "5a8130d129a14e61ad80b8dfe2aac9ee",
      "78e38325373747b7b9296fac648b028c",
      "339e884994744f6b86127ef7e554e712",
      "1a8c94d0b8ba4ff1858c85c986d42edb",
      "55bb5450d4ea4fc6a3c3fc5c6deb3883",
      "bb94fc7f0eac498db98bcd9d25c77198",
      "e381fbcebbf844ee8835fed2c4e77b5f",
      "073241a9b6354907bb0ad029adefd5d1",
      "25e627ef4d0b40a1b4b09d707ca29d8e",
      "0b20511c9e75447eb4f700bce8c077f9",
      "7ae26e08784b4533939848188bab1b8a",
      "0047d520ad694ec094877b32007e20ef",
      "de5992a1f6944c488d8d88160ff9baac",
      "aa4519ff03bd4c0eb7a220ac02aef9f7",
      "e9497f6f5f374288a638cbfba91c92cf",
      "8069f323370447e48c918d7093abe396",
      "fd7cd179aadc4c2a93d17764c367752e",
      "e1be8409510d4758a96c0b47a62582cc",
      "20c45ee72e4343b8b250d698ca3e5966",
      "a83d2d1f68d148219b90767fac35217d",
      "224b3a28d7ba44a5996f44717d1dd833",
      "1ff37d9296ee4202a0cca0251131eff2",
      "7fbd375ab9c642d58ad50aa906f754bd",
      "770278be97c54dc6b1ca46147e8055f6",
      "099301b553704ee5ad7816af05d163e5",
      "10a71c40494e48fb8cbb6ed45fc9afd9",
      "08a71267389649b8a2ba38789834a82d",
      "593855b97a54479c916e10d93f3dce32",
      "624dc1e05cb14d7f9993720102bdfbc3",
      "d91c19682ba64d73b432043989d2002e",
      "16ecf93e34164f5295c01f52cd4ecdbf",
      "8fa71abd28534900b85d484162f35aa7",
      "a5dfb567e550478faf7c5c59ad8c229b",
      "931f7dfe273544b2a9c868d63ddd4afe",
      "b0a9d1157610443398825bb491703bac",
      "9953177171b344a9b53bfc586bb8e7db",
      "68cb7b2197614ede8dc8ada218596591",
      "bdff9ee7fb534296ad849952d592eded",
      "681081b14cea430ca58408090a751a2e",
      "5833c0be5ee049e59a1249bb1e54ab37",
      "8607c4311fb94a7bac0ca1127a4457e1",
      "8c80cb0a7bd742418b24910806387f28",
      "ce764fcf7207455d8cf963a62a7b18cd"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-07-26T19:25:31.998492Z",
     "iopub.status.busy": "2025-07-26T19:25:31.997831Z",
     "iopub.status.idle": "2025-07-26T19:25:40.796754Z",
     "shell.execute_reply": "2025-07-26T19:25:40.796139Z",
     "shell.execute_reply.started": "2025-07-26T19:25:31.998465Z"
    },
    "id": "oL5doQOWVHK9",
    "outputId": "b3097ed1-1551-45de-85f9-0383b484ff09",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5667cc5d5e045b3b7d581b597c67611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa69007d8764386bc6ace6345d89530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a62dcfd95c495ba931c62da34c71b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "valid.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfdebe6c4b045338f7f7ca56b7ab6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698a416122284b4c903f373eaadd437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/272115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a787c7cd2e4a10a27e3b4a5f61fb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/17535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa643f264ea4c50a61f1fd6e7d122f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/20466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': '/m/027rn', 'relation': '/m/06cx9', 'tail': '/location/country/form_of_government'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import tqdm as notebook_tqdm\n",
    "# FB15k-237 from HuggingFace\n",
    "dataset = load_dataset(\"VLyb/FB15k-237\")\n",
    "\n",
    "train_triples = dataset[\"train\"]\n",
    "test_triples = dataset[\"test\"]\n",
    "valid_triples = dataset[\"validation\"]\n",
    "print(train_triples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-26T19:26:36.790456Z",
     "iopub.status.busy": "2025-07-26T19:26:36.790157Z",
     "iopub.status.idle": "2025-07-26T19:26:36.795439Z",
     "shell.execute_reply": "2025-07-26T19:26:36.794738Z",
     "shell.execute_reply.started": "2025-07-26T19:26:36.790436Z"
    },
    "id": "Tp1n_ekWGngG",
    "outputId": "f104751b-06b5-4b3e-8db4-1454dcdd0b4b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': '/m/027rn', 'relation': '/m/06cx9', 'tail': '/location/country/form_of_government'}\n",
      "{'head': '/m/017dcd', 'relation': '/m/06v8s0', 'tail': '/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor'}\n",
      "{'head': '/m/07s9rl0', 'relation': '/m/0170z3', 'tail': '/media_common/netflix_genre/titles'}\n"
     ]
    }
   ],
   "source": [
    "print(train_triples[0])\n",
    "print(train_triples[1])\n",
    "print(train_triples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlHdCpQiHMsy"
   },
   "source": [
    "As we see here it looks like the relation and tail are inverted. This makes the evaluation of model performance meaningless if it is not corrected. Therefore we will fix it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:26:05.615469Z",
     "iopub.status.busy": "2025-07-26T19:26:05.615206Z",
     "iopub.status.idle": "2025-07-26T19:26:21.393481Z",
     "shell.execute_reply": "2025-07-26T19:26:21.392691Z",
     "shell.execute_reply.started": "2025-07-26T19:26:05.615451Z"
    },
    "id": "PTrRcfoVHWkr",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec5c3e87d064103b152bdd6840a46d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/272115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa280bd1812403e80e0c2e23458a48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4695c2bc995a47d6be24d84c137e5a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_fields(example):\n",
    "    return {\n",
    "        \"head\": example[\"head\"],\n",
    "        \"relation\": example[\"tail\"],\n",
    "        \"tail\": example[\"relation\"]\n",
    "    }\n",
    "\n",
    "train_dataset = dataset[\"train\"].map(fix_fields)\n",
    "valid_dataset = dataset[\"validation\"].map(fix_fields)\n",
    "test_dataset  = dataset[\"test\"].map(fix_fields)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:27:34.536511Z",
     "iopub.status.busy": "2025-07-26T19:27:34.536255Z",
     "iopub.status.idle": "2025-07-26T19:27:34.545390Z",
     "shell.execute_reply": "2025-07-26T19:27:34.544695Z",
     "shell.execute_reply.started": "2025-07-26T19:27:34.536495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_triples = train_dataset.select(range(10000))\n",
    "valid_triples = valid_dataset.select(range(2000))\n",
    "test_triples  = test_dataset.select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-26T19:27:36.731461Z",
     "iopub.status.busy": "2025-07-26T19:27:36.730864Z",
     "iopub.status.idle": "2025-07-26T19:27:36.736253Z",
     "shell.execute_reply": "2025-07-26T19:27:36.735368Z",
     "shell.execute_reply.started": "2025-07-26T19:27:36.731436Z"
    },
    "id": "e2fvJxLvHXyq",
    "outputId": "e2217ed7-90d1-4831-baeb-531f47156f53",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': '/m/027rn', 'relation': '/location/country/form_of_government', 'tail': '/m/06cx9'}\n",
      "{'head': '/m/017dcd', 'relation': '/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor', 'tail': '/m/06v8s0'}\n",
      "{'head': '/m/07s9rl0', 'relation': '/media_common/netflix_genre/titles', 'tail': '/m/0170z3'}\n"
     ]
    }
   ],
   "source": [
    "print(train_triples[0])\n",
    "print(train_triples[1])\n",
    "print(train_triples[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:27:39.462003Z",
     "iopub.status.busy": "2025-07-26T19:27:39.461381Z",
     "iopub.status.idle": "2025-07-26T19:27:39.470668Z",
     "shell.execute_reply": "2025-07-26T19:27:39.469982Z",
     "shell.execute_reply.started": "2025-07-26T19:27:39.461982Z"
    },
    "id": "QHIouv_z1zt_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# use only a subset of the data. This is done as my laptop does not have a GPU and therfore struggles\n",
    "subset_size = 10000\n",
    "\n",
    "train_triples = train_triples.select(range(subset_size))\n",
    "valid_triples = valid_triples.select(range(2000))\n",
    "test_triples = test_triples.select(range(2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "addbpc1h-Qty"
   },
   "source": [
    "* load the mapping of entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-07-26T19:27:42.238634Z",
     "iopub.status.busy": "2025-07-26T19:27:42.238352Z",
     "iopub.status.idle": "2025-07-26T19:27:43.065589Z",
     "shell.execute_reply": "2025-07-26T19:27:43.064830Z",
     "shell.execute_reply.started": "2025-07-26T19:27:42.238615Z"
    },
    "id": "pzS_uixP_cZZ",
    "outputId": "4670166a-a68e-495f-cc21-a12963586e1c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-26 19:27:42--  https://raw.githubusercontent.com/yao8839836/kg-bert/master/data/FB15k-237/entity2text.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 392383 (383K) [text/plain]\n",
      "Saving to: ‘entity2text.txt’\n",
      "\n",
      "entity2text.txt     100%[===================>] 383.19K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2025-07-26 19:27:42 (63.6 MB/s) - ‘entity2text.txt’ saved [392383/392383]\n",
      "\n",
      "--2025-07-26 19:27:42--  https://raw.githubusercontent.com/yao8839836/kg-bert/master/data/FB15k-237/relation2text.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29130 (28K) [text/plain]\n",
      "Saving to: ‘relation2text.txt’\n",
      "\n",
      "relation2text.txt   100%[===================>]  28.45K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-26 19:27:42 (71.1 MB/s) - ‘relation2text.txt’ saved [29130/29130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/yao8839836/kg-bert/master/data/FB15k-237/entity2text.txt\n",
    "!wget https://raw.githubusercontent.com/yao8839836/kg-bert/master/data/FB15k-237/relation2text.txt\n",
    "\n",
    "# Load entity names\n",
    "entity_map = {}\n",
    "with open(\"entity2text.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        eid, name = line.strip().split('\\t')\n",
    "        entity_map[eid] = name\n",
    "\n",
    "# Load relation names\n",
    "relation_map = {}\n",
    "with open(\"relation2text.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rid, name = line.strip().split('\\t')\n",
    "        relation_map[rid] = name\n",
    "\n",
    "\n",
    "def triple_to_sentence(h, r, t, entity_map = entity_map, relation_map = relation_map):\n",
    "    h_text = entity_map.get(h, h)\n",
    "    r_text = relation_map.get(r, r.replace(\"/\", \" \").replace(\"_\", \" \"))\n",
    "    t_text = entity_map.get(t, t)\n",
    "    return f\"{h_text} {r_text} {t_text}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-07-26T19:27:47.279204Z",
     "iopub.status.busy": "2025-07-26T19:27:47.278142Z",
     "iopub.status.idle": "2025-07-26T19:28:25.607556Z",
     "shell.execute_reply": "2025-07-26T19:28:25.606547Z",
     "shell.execute_reply.started": "2025-07-26T19:27:47.279174Z"
    },
    "id": "B9Qau4qQVHK-",
    "outputId": "afc98bfb-b797-447e-e9cc-4cc5dd0ea1ed",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635c6892e43b4415bab6f8eed2297455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968fb162d6b04d88a3d42b358b3eed33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933b241913d14eea97173f6fae439dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72bbb8042f140e8accb02a9e47e5b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 19:28:09.264207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753558089.542742      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753558089.628560      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86ffaf962c44a778dd8244013e2bd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ModernBertModel(\n",
       "  (embeddings): ModernBertEmbeddings(\n",
       "    (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): ModernBertEncoderLayer(\n",
       "      (attn_norm): Identity()\n",
       "      (attn): ModernBertAttention(\n",
       "        (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (rotary_emb): ModernBertRotaryEmbedding()\n",
       "        (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_drop): Identity()\n",
       "      )\n",
       "      (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ModernBertMLP(\n",
       "        (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (act): GELUActivation()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1-21): 21 x ModernBertEncoderLayer(\n",
       "      (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): ModernBertAttention(\n",
       "        (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (rotary_emb): ModernBertRotaryEmbedding()\n",
       "        (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_drop): Identity()\n",
       "      )\n",
       "      (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): ModernBertMLP(\n",
       "        (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "        (act): GELUActivation()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# load model and tokenizer -- ModernBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\", trust_remote_code=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:33.518094Z",
     "iopub.status.busy": "2025-07-26T19:28:33.517226Z",
     "iopub.status.idle": "2025-07-26T19:28:33.523810Z",
     "shell.execute_reply": "2025-07-26T19:28:33.523085Z",
     "shell.execute_reply.started": "2025-07-26T19:28:33.518062Z"
    },
    "id": "3f8NqfAIVHK-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# score a sentence -- we would like a higher positive or negative score dependinf on the sentence\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_sentence(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    score = torch.norm(cls_embedding, p=2, dim=1)\n",
    "    return score.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:35.966322Z",
     "iopub.status.busy": "2025-07-26T19:28:35.965651Z",
     "iopub.status.idle": "2025-07-26T19:28:36.400965Z",
     "shell.execute_reply": "2025-07-26T19:28:36.400242Z",
     "shell.execute_reply.started": "2025-07-26T19:28:35.966287Z"
    },
    "id": "JUZRRy5-VHK_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# get a set containing all the entities in any of the three sets\n",
    "all_entities = set()\n",
    "\n",
    "for split in [train_triples, test_triples, valid_triples]:\n",
    "    for row in split:\n",
    "        all_entities.update([row[\"head\"], row[\"tail\"]])\n",
    "all_entities = list(all_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:38.313781Z",
     "iopub.status.busy": "2025-07-26T19:28:38.313494Z",
     "iopub.status.idle": "2025-07-26T19:28:38.813403Z",
     "shell.execute_reply": "2025-07-26T19:28:38.812447Z",
     "shell.execute_reply.started": "2025-07-26T19:28:38.313762Z"
    },
    "id": "OrEjdbPGVHK_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# corrupt either the head or the tail\n",
    "def corrupt_triple(triple, entity_list):\n",
    "    head, relation, tail = triple\n",
    "    if random.random() < 0.5:\n",
    "        # Corrupt tail\n",
    "        corrupted = (head, relation, random.choice(entity_list))\n",
    "    else:\n",
    "        # Corrupt head\n",
    "        corrupted = (random.choice(entity_list), relation, tail)\n",
    "    return corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:40.754996Z",
     "iopub.status.busy": "2025-07-26T19:28:40.754661Z",
     "iopub.status.idle": "2025-07-26T19:28:41.098540Z",
     "shell.execute_reply": "2025-07-26T19:28:41.097670Z",
     "shell.execute_reply.started": "2025-07-26T19:28:40.754942Z"
    },
    "id": "b2jyr0e-VHK_",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score: 36.1393\n",
      "Negative score: 36.1106\n"
     ]
    }
   ],
   "source": [
    "# Pick a positive triple\n",
    "pos = test_triples[0]\n",
    "pos_triple = (pos[\"head\"], pos[\"relation\"], pos[\"tail\"])\n",
    "\n",
    "# Corrupt it\n",
    "neg_triple = corrupt_triple(pos_triple, all_entities)\n",
    "\n",
    "# Convert to sentences\n",
    "pos_sentence = triple_to_sentence(*pos_triple, entity_map, relation_map)\n",
    "neg_sentence = triple_to_sentence(*neg_triple, entity_map, relation_map)\n",
    "\n",
    "# Score both\n",
    "pos_score = score_sentence(pos_sentence)\n",
    "neg_score = score_sentence(neg_sentence)\n",
    "\n",
    "print(f\"Positive score: {pos_score:.4f}\")\n",
    "print(f\"Negative score: {neg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rmuS3JnVHK_"
   },
   "source": [
    "using bert alone, with a basic loss function and no training shows that the model is not attuned enough to this type of task and the difference between positive (indicating that the triple is correct) and negative (triple is incorrect) scores is too mild for it to be acceptable. Therefore some steps need to be taken in order to make it better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3XeebcOVHLB"
   },
   "source": [
    "- build a dataset which contains the triples labelled (corrupted or not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:43.851422Z",
     "iopub.status.busy": "2025-07-26T19:28:43.850694Z",
     "iopub.status.idle": "2025-07-26T19:28:43.856899Z",
     "shell.execute_reply": "2025-07-26T19:28:43.855977Z",
     "shell.execute_reply.started": "2025-07-26T19:28:43.851391Z"
    },
    "id": "jbkqjPsyVHLB",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the lenght of the triples is correct\n",
    "len(train_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:46.093002Z",
     "iopub.status.busy": "2025-07-26T19:28:46.092633Z",
     "iopub.status.idle": "2025-07-26T19:28:46.099110Z",
     "shell.execute_reply": "2025-07-26T19:28:46.098186Z",
     "shell.execute_reply.started": "2025-07-26T19:28:46.092959Z"
    },
    "id": "FvLcYO7sVHLB",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': '/m/027rn',\n",
       " 'relation': '/location/country/form_of_government',\n",
       " 'tail': '/m/06cx9'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgnuSfGY_c8O"
   },
   "source": [
    "Since we are using modernbert, the entities and relations need to make sense to be able to use its pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:48.599234Z",
     "iopub.status.busy": "2025-07-26T19:28:48.598205Z",
     "iopub.status.idle": "2025-07-26T19:28:48.605445Z",
     "shell.execute_reply": "2025-07-26T19:28:48.604680Z",
     "shell.execute_reply.started": "2025-07-26T19:28:48.599198Z"
    },
    "id": "GwsY2sPjVHLC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# corrupt either the head or the tail\n",
    "def corrupt_triple2(triple, entity_list):\n",
    "    h, r, t = triple['head'], triple['relation'], triple['tail']\n",
    "    if random.random() < 0.5:\n",
    "        corrupted = (random.choice(entity_list), r, t)\n",
    "    else:\n",
    "        corrupted = (h, r, random.choice(entity_list))\n",
    "    return corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:51.512367Z",
     "iopub.status.busy": "2025-07-26T19:28:51.511199Z",
     "iopub.status.idle": "2025-07-26T19:28:52.017695Z",
     "shell.execute_reply": "2025-07-26T19:28:52.016807Z",
     "shell.execute_reply.started": "2025-07-26T19:28:51.512331Z"
    },
    "id": "77Z3QDC2NNGW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_labeled_data(triples, all_entities, corrupt_fn, entity_map, relation_map):\n",
    "    data = []\n",
    "    for triple in triples:\n",
    "        h, r, t = triple[\"head\"], triple[\"relation\"], triple[\"tail\"]\n",
    "        pos_sentence = triple_to_sentence(h, r, t, entity_map, relation_map)\n",
    "        data.append((pos_sentence, 1))\n",
    "\n",
    "        ch, cr, ct = corrupt_fn(triple, all_entities)\n",
    "        neg_sentence = triple_to_sentence(ch, cr, ct, entity_map, relation_map)\n",
    "        data.append((neg_sentence, 0))\n",
    "    return data\n",
    "\n",
    "# create the proper data to train, validate and test the model\n",
    "# each is going to contain double the data they start with as for every triple we have a positive and a negative\n",
    "train_data = make_labeled_data(train_triples, all_entities, corrupt_triple2, entity_map, relation_map)\n",
    "val_data = make_labeled_data(valid_triples, all_entities, corrupt_triple2, entity_map, relation_map)\n",
    "test_data = make_labeled_data(test_triples, all_entities, corrupt_triple2, entity_map, relation_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:28:54.512736Z",
     "iopub.status.busy": "2025-07-26T19:28:54.512441Z",
     "iopub.status.idle": "2025-07-26T19:29:01.642246Z",
     "shell.execute_reply": "2025-07-26T19:29:01.641388Z",
     "shell.execute_reply.started": "2025-07-26T19:28:54.512714Z"
    },
    "id": "4ItAw1zIN1WN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "def tokenize_data(data):\n",
    "    tokenized = []\n",
    "    for sentence, label in data:\n",
    "        encoded = tokenizer(sentence, truncation=True, padding='max_length', max_length=32, return_tensors='pt')\n",
    "        tokenized.append({\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.float)\n",
    "        })\n",
    "    return tokenized\n",
    "\n",
    "train_tokenized = tokenize_data(train_data)\n",
    "val_tokenized = tokenize_data(val_data)\n",
    "test_tokenized = tokenize_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBrybpziVHLC"
   },
   "source": [
    "- create a torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4RQXRN_9VHLC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# tokenized_data = []\n",
    "# for sentence, label in data:\n",
    "#     enc = tokenizer(\n",
    "#         sentence,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#         max_length=32,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     tokenized_data.append({\n",
    "#         \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "#         \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "#         \"label\": torch.tensor(label, dtype=torch.float)\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:29:57.825140Z",
     "iopub.status.busy": "2025-07-26T19:29:57.824443Z",
     "iopub.status.idle": "2025-07-26T19:29:58.452219Z",
     "shell.execute_reply": "2025-07-26T19:29:58.451381Z",
     "shell.execute_reply.started": "2025-07-26T19:29:57.825108Z"
    },
    "id": "okh6jaz4VHLC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:29:59.349751Z",
     "iopub.status.busy": "2025-07-26T19:29:59.349041Z",
     "iopub.status.idle": "2025-07-26T19:29:59.355118Z",
     "shell.execute_reply": "2025-07-26T19:29:59.354223Z",
     "shell.execute_reply.started": "2025-07-26T19:29:59.349719Z"
    },
    "id": "GioRlm1baQDB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"input_ids\": torch.stack([item[\"input_ids\"] for item in batch]),\n",
    "        \"attention_mask\": torch.stack([item[\"attention_mask\"] for item in batch]),\n",
    "        \"label\": torch.stack([item[\"label\"] for item in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:01.949704Z",
     "iopub.status.busy": "2025-07-26T19:30:01.949427Z",
     "iopub.status.idle": "2025-07-26T19:30:01.955923Z",
     "shell.execute_reply": "2025-07-26T19:30:01.955012Z",
     "shell.execute_reply.started": "2025-07-26T19:30:01.949684Z"
    },
    "id": "8kMWsYbKRWA_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PreTokenizedDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "train_loader = DataLoader(PreTokenizedDataset(train_tokenized), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(PreTokenizedDataset(val_tokenized), batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(PreTokenizedDataset(test_tokenized), batch_size=32, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4YZAiCbVHLC"
   },
   "source": [
    "- add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:04.139035Z",
     "iopub.status.busy": "2025-07-26T19:30:04.138736Z",
     "iopub.status.idle": "2025-07-26T19:30:04.144326Z",
     "shell.execute_reply": "2025-07-26T19:30:04.143565Z",
     "shell.execute_reply.started": "2025-07-26T19:30:04.139015Z"
    },
    "id": "Q1Efus2DVHLC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class TripleClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.encoder = base_model\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(cls).squeeze(-1)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:06.365796Z",
     "iopub.status.busy": "2025-07-26T19:30:06.365495Z",
     "iopub.status.idle": "2025-07-26T19:30:07.011468Z",
     "shell.execute_reply": "2025-07-26T19:30:07.010585Z",
     "shell.execute_reply.started": "2025-07-26T19:30:06.365774Z"
    },
    "id": "gUaoujLYVHLD",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"answerdotai/ModernBERT-base\", trust_remote_code=True)\n",
    "model = TripleClassifier(base_model)\n",
    "model.to(device)\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNTFKKZlVHLD"
   },
   "source": [
    "- train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:10.004626Z",
     "iopub.status.busy": "2025-07-26T19:30:10.004304Z",
     "iopub.status.idle": "2025-07-26T19:30:10.013143Z",
     "shell.execute_reply": "2025-07-26T19:30:10.012420Z",
     "shell.execute_reply.started": "2025-07-26T19:30:10.004602Z"
    },
    "id": "CvrTTxEoVHLD",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripleClassifier(\n",
       "  (encoder): ModernBertModel(\n",
       "    (embeddings): ModernBertEmbeddings(\n",
       "      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ModernBertEncoderLayer(\n",
       "        (attn_norm): Identity()\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertRotaryEmbedding()\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1-21): 21 x ModernBertEncoderLayer(\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ModernBertAttention(\n",
       "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (rotary_emb): ModernBertRotaryEmbedding()\n",
       "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (out_drop): Identity()\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModernBertMLP(\n",
       "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (act): GELUActivation()\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVrokifCVHLD"
   },
   "source": [
    "- this is not good, let us try to use train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjwXCsHZR50h",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=2e-1)\n",
    "# criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:13.091359Z",
     "iopub.status.busy": "2025-07-26T19:30:13.090757Z",
     "iopub.status.idle": "2025-07-26T19:30:13.098698Z",
     "shell.execute_reply": "2025-07-26T19:30:13.097948Z",
     "shell.execute_reply.started": "2025-07-26T19:30:13.091328Z"
    },
    "id": "WL3bw94vRxtr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_examples += labels.size(0)\n",
    "\n",
    "    model.train()\n",
    "    accuracy = total_correct / total_examples\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:30:30.461993Z",
     "iopub.status.busy": "2025-07-26T19:30:30.461697Z",
     "iopub.status.idle": "2025-07-26T19:30:30.469434Z",
     "shell.execute_reply": "2025-07-26T19:30:30.468555Z",
     "shell.execute_reply.started": "2025-07-26T19:30:30.461971Z"
    },
    "id": "LW9jo8U_cNqq",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader))[\"input_ids\"].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:32:16.049177Z",
     "iopub.status.busy": "2025-07-26T19:32:16.048851Z",
     "iopub.status.idle": "2025-07-26T19:32:16.053299Z",
     "shell.execute_reply": "2025-07-26T19:32:16.052291Z",
     "shell.execute_reply.started": "2025-07-26T19:32:16.049156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:32:17.872806Z",
     "iopub.status.busy": "2025-07-26T19:32:17.872144Z",
     "iopub.status.idle": "2025-07-26T19:40:46.088026Z",
     "shell.execute_reply": "2025-07-26T19:40:46.087165Z",
     "shell.execute_reply.started": "2025-07-26T19:32:17.872773Z"
    },
    "id": "qkUH4B3ZRyVb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT compiled_embeddings /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 204 \n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:18.208000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:19.402000 36 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT compiled_mlp /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 523 \n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:19.502000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /usr/local/lib/python3.11/dist-packages/transformers/models/modernbert/modeling_modernbert.py line 237 \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:20.108000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] WON'T CONVERT forward /usr/local/lib/python3.11/dist-packages/transformers/activations.py line 68 \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] due to: \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] Traceback (most recent call last):\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 1164, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     result = self._inner_convert(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 547, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 986, in _compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 715, in compile_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_utils_internal.py\", line 95, in wrapper_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return function(*args, **kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 750, in _compile_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     out_code = transform_code_object(code, transform)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1361, in transform_code_object\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     transformations(instructions, code_options)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 231, in _fn\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return fn(*args, **kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\", line 662, in transform\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     tracer.run()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2868, in run\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     super().run()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 1052, in run\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     while self.step():\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]           ^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 962, in step\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3048, in RETURN_VALUE\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._return(inst)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\", line 3033, in _return\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.output.compile_subgraph(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1101, in compile_subgraph\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.compile_and_call_fx_graph(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1382, in compile_and_call_fx_graph\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1432, in call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self._call_user_compiler(gm)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1483, in _call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/output_graph.py\", line 1462, in _call_user_compiler\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 130, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 2340, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1863, in compile_fx\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return aot_autograd(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/backends/common.py\", line 83, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1155, in aot_module_simplified\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = dispatch_and_compile()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 1131, in dispatch_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 580, in create_aot_dispatcher_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return _create_aot_dispatcher_function(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 830, in _create_aot_dispatcher_function\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                                ^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 678, in aot_dispatch_autograd\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\", line 489, in __call__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self.compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1741, in fw_compiler_base\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return inner_compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 569, in compile_fx_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/repro/after_aot.py\", line 102, in debug_wrapper\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 685, in _compile_fx_inner\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     mb_compiled_graph = fx_codegen_and_compile(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1129, in fx_codegen_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/compile_fx.py\", line 1044, in codegen_and_compile\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     compiled_fn = graph.compile_to_module().call\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2027, in compile_to_module\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return self._compile_to_module()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 2033, in _compile_to_module\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                                                              ^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/graph.py\", line 1964, in codegen\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.scheduler = Scheduler(self.operations)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1798, in __init__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._init(nodes)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in _init\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1816, in <listcomp>\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 1947, in create_scheduler_node\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     return SchedulerNode(self, node)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 893, in __init__\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self._compute_attrs()\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 907, in _compute_attrs\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     group_fn = self.scheduler.get_backend(device).group_fn\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3441, in get_backend\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     self.backends[device] = self.create_backend(device)\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]   File \"/usr/local/lib/python3.11/dist-packages/torch/_inductor/scheduler.py\", line 3428, in create_backend\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233]     raise RuntimeError(\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] RuntimeError: Found Tesla P100-PCIE-16GB which is too old to be supported by the triton GPU compiler, which is used as the backend. Triton only supports devices of CUDA Capability >= 7.0, but your device is of CUDA capability 6.0\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] \n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0726 19:32:20.363000 36 torch/_dynamo/convert_frame.py:1233] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.6965 | Train Acc: 0.5186 | Val Loss: 0.6909 | Val Acc: 0.5415\n",
      "Epoch 2 | Train Loss: 0.6588 | Train Acc: 0.5916 | Val Loss: 0.5554 | Val Acc: 0.7318\n",
      "Epoch 3 | Train Loss: 0.4586 | Train Acc: 0.7833 | Val Loss: 0.3873 | Val Acc: 0.8320\n",
      "Epoch 4 | Train Loss: 0.3113 | Train Acc: 0.8689 | Val Loss: 0.3119 | Val Acc: 0.8705\n",
      "Epoch 5 | Train Loss: 0.2329 | Train Acc: 0.9084 | Val Loss: 0.3129 | Val Acc: 0.8718\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_train_loss = 0\n",
    "    total_train_correct = 0\n",
    "    total_train_examples = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()\n",
    "        total_train_correct += (preds == labels).sum().item()\n",
    "        total_train_examples += labels.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_acc = total_train_correct / total_train_examples\n",
    "\n",
    "    avg_val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:41:34.300387Z",
     "iopub.status.busy": "2025-07-26T19:41:34.299588Z",
     "iopub.status.idle": "2025-07-26T19:41:40.028561Z",
     "shell.execute_reply": "2025-07-26T19:41:40.027883Z",
     "shell.execute_reply.started": "2025-07-26T19:41:34.300360Z"
    },
    "id": "vx_sdLTZR8qF",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3238 | Test Accuracy: 0.8678\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:41:44.166985Z",
     "iopub.status.busy": "2025-07-26T19:41:44.166653Z",
     "iopub.status.idle": "2025-07-26T19:41:49.907702Z",
     "shell.execute_reply": "2025-07-26T19:41:49.906849Z",
     "shell.execute_reply.started": "2025-07-26T19:41:44.166925Z"
    },
    "id": "sPKoC0Tv6-jE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_preds.extend((probs > 0.5).float().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:41:58.702934Z",
     "iopub.status.busy": "2025-07-26T19:41:58.702639Z",
     "iopub.status.idle": "2025-07-26T19:41:58.724900Z",
     "shell.execute_reply": "2025-07-26T19:41:58.724020Z",
     "shell.execute_reply.started": "2025-07-26T19:41:58.702913Z"
    },
    "id": "C8Gjra8a7Euw",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9075    0.8190    0.8610      2000\n",
      "         1.0     0.8351    0.9165    0.8739      2000\n",
      "\n",
      "    accuracy                         0.8678      4000\n",
      "   macro avg     0.8713    0.8678    0.8674      4000\n",
      "weighted avg     0.8713    0.8678    0.8674      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:42:11.830373Z",
     "iopub.status.busy": "2025-07-26T19:42:11.829663Z",
     "iopub.status.idle": "2025-07-26T19:42:11.843107Z",
     "shell.execute_reply": "2025-07-26T19:42:11.842327Z",
     "shell.execute_reply.started": "2025-07-26T19:42:11.830330Z"
    },
    "id": "qynQF6fE7Lia",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(all_labels, all_probs)\n",
    "print(f\"ROC AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:42:14.681603Z",
     "iopub.status.busy": "2025-07-26T19:42:14.680708Z",
     "iopub.status.idle": "2025-07-26T19:42:14.948160Z",
     "shell.execute_reply": "2025-07-26T19:42:14.947226Z",
     "shell.execute_reply.started": "2025-07-26T19:42:14.681568Z"
    },
    "id": "u369O9MY7Mq0",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATHxlGZ-7dpL"
   },
   "source": [
    "**Analysis of results**:\n",
    "\n",
    "These seem to be quite high, especially for a binary classification task and therefore we are brought to ask ourselves the question wether this is a little too good to be true.\n",
    "\n",
    "Still, I would like to propose the following reasons as to why this might be happening:\n",
    "\n",
    "\n",
    "*   Having corrupted relations instead of proper negative ones makes for an easier task to complete for the model, which means that we would generally expect a higher test accuracy\n",
    "* Having well-formed inputs with BERT encoders (like we have here with the mapping of entities and relations) takes advantage of the pretraining, and therefore makes the task easier\n",
    "*   The patterns of positive and negative examples are fairly similar, meaning that the model learns in a much smoother way\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T19:42:18.375704Z",
     "iopub.status.busy": "2025-07-26T19:42:18.374844Z",
     "iopub.status.idle": "2025-07-26T19:42:18.580159Z",
     "shell.execute_reply": "2025-07-26T19:42:18.579274Z",
     "shell.execute_reply.started": "2025-07-26T19:42:18.375669Z"
    },
    "id": "e_cMn3nDD7vp",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM4lWJf_9f83"
   },
   "source": [
    "**Possible next steps**\n",
    "\n",
    "A good idea would be to see if we can further corrupt the triples in a much more disordered way, for example mixing up entities and relations or even adding noise to see how well the model performs. I could also show that without actual phrases so if the model sees gibberish it performs really badly, this could be something to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X_gs6rsVHLF",
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0047d520ad694ec094877b32007e20ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8069f323370447e48c918d7093abe396",
      "placeholder": "​",
      "style": "IPY_MODEL_fd7cd179aadc4c2a93d17764c367752e",
      "value": "Generating train split: 100%"
     }
    },
    "039f6eb2e4c8465893abc04dd897fd63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "073241a9b6354907bb0ad029adefd5d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07f665e4e3324af1a63973df96b2f74e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08a71267389649b8a2ba38789834a82d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "099301b553704ee5ad7816af05d163e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16ecf93e34164f5295c01f52cd4ecdbf",
      "placeholder": "​",
      "style": "IPY_MODEL_8fa71abd28534900b85d484162f35aa7",
      "value": " 17535/17535 [00:00&lt;00:00, 141041.04 examples/s]"
     }
    },
    "0b20511c9e75447eb4f700bce8c077f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e197d7762c445d48d85a842fb6b0fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f29954f9f3514f2faa4b88c1a05be0f0",
      "placeholder": "​",
      "style": "IPY_MODEL_1b81b0b7f0f744868f10d62081e60db1",
      "value": "train.csv: 100%"
     }
    },
    "10a71c40494e48fb8cbb6ed45fc9afd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "161300e40b1744e792190574d8f1ae4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_908cf0621e5f449d848a8e0358103aae",
       "IPY_MODEL_3f03cb71ffa84260a55747417ccd5b7e",
       "IPY_MODEL_2e86fc6f454f4520987cbb74c19aeb58"
      ],
      "layout": "IPY_MODEL_49e0b0c891f7425c9a7f236498a4c8e3"
     }
    },
    "16c5cad737434496b160b58c0995a0fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "16ecf93e34164f5295c01f52cd4ecdbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a8c94d0b8ba4ff1858c85c986d42edb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b81b0b7f0f744868f10d62081e60db1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff37d9296ee4202a0cca0251131eff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fbd375ab9c642d58ad50aa906f754bd",
       "IPY_MODEL_770278be97c54dc6b1ca46147e8055f6",
       "IPY_MODEL_099301b553704ee5ad7816af05d163e5"
      ],
      "layout": "IPY_MODEL_10a71c40494e48fb8cbb6ed45fc9afd9"
     }
    },
    "20c45ee72e4343b8b250d698ca3e5966": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "224b3a28d7ba44a5996f44717d1dd833": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25e627ef4d0b40a1b4b09d707ca29d8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e86fc6f454f4520987cbb74c19aeb58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6aa5e640ee7c42d88578521b0fde8b5f",
      "placeholder": "​",
      "style": "IPY_MODEL_16c5cad737434496b160b58c0995a0fa",
      "value": " 27.0/27.0 [00:00&lt;00:00, 928B/s]"
     }
    },
    "339e884994744f6b86127ef7e554e712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25e627ef4d0b40a1b4b09d707ca29d8e",
      "placeholder": "​",
      "style": "IPY_MODEL_0b20511c9e75447eb4f700bce8c077f9",
      "value": " 1.50M/? [00:00&lt;00:00, 15.9MB/s]"
     }
    },
    "3d89dbecab9a451386701db0fb8f1ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ccea143913c14cf9b6b6d36ba4537003",
       "IPY_MODEL_d418908020b641148e4150da379e32a5",
       "IPY_MODEL_4fa04f2cb0344c36add0912d6fea57e7"
      ],
      "layout": "IPY_MODEL_7b8125dc670f48bd8c43ac9ba185446b"
     }
    },
    "3f03cb71ffa84260a55747417ccd5b7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f62831d6dec4c5199029f6678a78c5e",
      "max": 27,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07f665e4e3324af1a63973df96b2f74e",
      "value": 27
     }
    },
    "49e0b0c891f7425c9a7f236498a4c8e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f5d3f3e1bc643a886f348789e7bf52d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4fa04f2cb0344c36add0912d6fea57e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd4c6764b9ab4ef98fa42f8caa3c41b0",
      "placeholder": "​",
      "style": "IPY_MODEL_d9841c70b30640438b97a2d24512d3cc",
      "value": " 1.29M/? [00:00&lt;00:00, 14.7MB/s]"
     }
    },
    "5182a1048b0f46e7b9b3087f64895c75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55bb5450d4ea4fc6a3c3fc5c6deb3883": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5833c0be5ee049e59a1249bb1e54ab37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "593855b97a54479c916e10d93f3dce32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a8130d129a14e61ad80b8dfe2aac9ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55bb5450d4ea4fc6a3c3fc5c6deb3883",
      "placeholder": "​",
      "style": "IPY_MODEL_bb94fc7f0eac498db98bcd9d25c77198",
      "value": "test.csv: "
     }
    },
    "5af62ace21344c0eb832f08763ccb2dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f62831d6dec4c5199029f6678a78c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "624dc1e05cb14d7f9993720102bdfbc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "681081b14cea430ca58408090a751a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68cb7b2197614ede8dc8ada218596591": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa5e640ee7c42d88578521b0fde8b5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770278be97c54dc6b1ca46147e8055f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_624dc1e05cb14d7f9993720102bdfbc3",
      "max": 17535,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d91c19682ba64d73b432043989d2002e",
      "value": 17535
     }
    },
    "78e38325373747b7b9296fac648b028c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e381fbcebbf844ee8835fed2c4e77b5f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_073241a9b6354907bb0ad029adefd5d1",
      "value": 1
     }
    },
    "7ae26e08784b4533939848188bab1b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0047d520ad694ec094877b32007e20ef",
       "IPY_MODEL_de5992a1f6944c488d8d88160ff9baac",
       "IPY_MODEL_aa4519ff03bd4c0eb7a220ac02aef9f7"
      ],
      "layout": "IPY_MODEL_e9497f6f5f374288a638cbfba91c92cf"
     }
    },
    "7b8125dc670f48bd8c43ac9ba185446b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fbd375ab9c642d58ad50aa906f754bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08a71267389649b8a2ba38789834a82d",
      "placeholder": "​",
      "style": "IPY_MODEL_593855b97a54479c916e10d93f3dce32",
      "value": "Generating validation split: 100%"
     }
    },
    "8069f323370447e48c918d7093abe396": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8607c4311fb94a7bac0ca1127a4457e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c80cb0a7bd742418b24910806387f28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fa71abd28534900b85d484162f35aa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "908cf0621e5f449d848a8e0358103aae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5182a1048b0f46e7b9b3087f64895c75",
      "placeholder": "​",
      "style": "IPY_MODEL_039f6eb2e4c8465893abc04dd897fd63",
      "value": "README.md: 100%"
     }
    },
    "931f7dfe273544b2a9c868d63ddd4afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdff9ee7fb534296ad849952d592eded",
      "placeholder": "​",
      "style": "IPY_MODEL_681081b14cea430ca58408090a751a2e",
      "value": "Generating test split: 100%"
     }
    },
    "946bc785bc2b463baf66d20f049725a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9953177171b344a9b53bfc586bb8e7db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c80cb0a7bd742418b24910806387f28",
      "placeholder": "​",
      "style": "IPY_MODEL_ce764fcf7207455d8cf963a62a7b18cd",
      "value": " 20466/20466 [00:00&lt;00:00, 95916.35 examples/s]"
     }
    },
    "9ca88f1eb1d343fba0d88360fcbfb35e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0e197d7762c445d48d85a842fb6b0fb3",
       "IPY_MODEL_c5176e5c1e2b4d128dfed67b6d42430e",
       "IPY_MODEL_f4faaa22ff194f5198526db3f9716768"
      ],
      "layout": "IPY_MODEL_a8ec611fd2164cb6af775b27be82e975"
     }
    },
    "a5dfb567e550478faf7c5c59ad8c229b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_931f7dfe273544b2a9c868d63ddd4afe",
       "IPY_MODEL_b0a9d1157610443398825bb491703bac",
       "IPY_MODEL_9953177171b344a9b53bfc586bb8e7db"
      ],
      "layout": "IPY_MODEL_68cb7b2197614ede8dc8ada218596591"
     }
    },
    "a83d2d1f68d148219b90767fac35217d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ec611fd2164cb6af775b27be82e975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa4519ff03bd4c0eb7a220ac02aef9f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a83d2d1f68d148219b90767fac35217d",
      "placeholder": "​",
      "style": "IPY_MODEL_224b3a28d7ba44a5996f44717d1dd833",
      "value": " 272115/272115 [00:01&lt;00:00, 233761.51 examples/s]"
     }
    },
    "b0a9d1157610443398825bb491703bac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5833c0be5ee049e59a1249bb1e54ab37",
      "max": 20466,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8607c4311fb94a7bac0ca1127a4457e1",
      "value": 20466
     }
    },
    "b68b364298f240c19c1dacbb6ab6d4ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b68e751ffd2d440c9c46cd9b16d51293": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b7c9a7fdfcda4691a3ecf60e24a35e67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a8130d129a14e61ad80b8dfe2aac9ee",
       "IPY_MODEL_78e38325373747b7b9296fac648b028c",
       "IPY_MODEL_339e884994744f6b86127ef7e554e712"
      ],
      "layout": "IPY_MODEL_1a8c94d0b8ba4ff1858c85c986d42edb"
     }
    },
    "bb94fc7f0eac498db98bcd9d25c77198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bbc04c2832f2418cb3941922ba0fe322": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd4c6764b9ab4ef98fa42f8caa3c41b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdd7a700989a4e8e8f8d6140e2df216e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdff9ee7fb534296ad849952d592eded": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5176e5c1e2b4d128dfed67b6d42430e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdd7a700989a4e8e8f8d6140e2df216e",
      "max": 21005196,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f5d3f3e1bc643a886f348789e7bf52d",
      "value": 21005196
     }
    },
    "ccea143913c14cf9b6b6d36ba4537003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbc04c2832f2418cb3941922ba0fe322",
      "placeholder": "​",
      "style": "IPY_MODEL_946bc785bc2b463baf66d20f049725a4",
      "value": "valid.csv: "
     }
    },
    "ce764fcf7207455d8cf963a62a7b18cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d418908020b641148e4150da379e32a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b68e751ffd2d440c9c46cd9b16d51293",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5af62ace21344c0eb832f08763ccb2dd",
      "value": 1
     }
    },
    "d91c19682ba64d73b432043989d2002e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9841c70b30640438b97a2d24512d3cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de5992a1f6944c488d8d88160ff9baac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1be8409510d4758a96c0b47a62582cc",
      "max": 272115,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20c45ee72e4343b8b250d698ca3e5966",
      "value": 272115
     }
    },
    "e1be8409510d4758a96c0b47a62582cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e381fbcebbf844ee8835fed2c4e77b5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "e9497f6f5f374288a638cbfba91c92cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f29954f9f3514f2faa4b88c1a05be0f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4faaa22ff194f5198526db3f9716768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b68b364298f240c19c1dacbb6ab6d4ab",
      "placeholder": "​",
      "style": "IPY_MODEL_f8d8517ab2d548e8b761f1e1c6020b6b",
      "value": " 21.0M/21.0M [00:00&lt;00:00, 27.9MB/s]"
     }
    },
    "f8d8517ab2d548e8b761f1e1c6020b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd7cd179aadc4c2a93d17764c367752e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
